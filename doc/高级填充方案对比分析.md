# gaoqing-T2æ¨¡æ€ç¼ºå¤±çš„é«˜çº§è§£å†³æ–¹æ¡ˆå¯¹æ¯”åˆ†æ

## ğŸ“Š æ–¹æ¡ˆæ¦‚è¿°

é’ˆå¯¹BPH-PCAæ•°æ®é›†ä¸­gaoqing-T2æ¨¡æ€ç¼ºå¤±é—®é¢˜ï¼Œé™¤äº†0å¡«å……æ–¹æ¡ˆå¤–ï¼Œè¿˜æœ‰å¤šç§æ›´é«˜çº§çš„è§£å†³æ–¹æ¡ˆã€‚æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æå„ç§æ–¹æ¡ˆçš„ä¼˜ç¼ºç‚¹å’Œé€‚ç”¨åœºæ™¯ã€‚

## ğŸ” è§£å†³æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆ1: 0å¡«å……ï¼ˆå·²å®ç°ï¼‰
**åŸç†**: ç”¨é›¶çŸ©é˜µå¡«å……ç¼ºå¤±çš„gaoqing-T2é€šé“
**ä¼˜åŠ¿**: 
- âœ… å®ç°ç®€å•ï¼Œè®¡ç®—å¿«é€Ÿ
- âœ… ä¿è¯æ•°æ®ä¸€è‡´æ€§
- âœ… nnU-Netèƒ½è‡ªåŠ¨é€‚åº”

**åŠ£åŠ¿**:
- âš ï¸ å®Œå…¨ä¸¢å¤±gaoqing-T2ä¿¡æ¯
- âš ï¸ å¯èƒ½å½±å“ç½‘ç»œå­¦ä¹ æ•ˆæœ

### æ–¹æ¡ˆ2: åŸºäºç›¸ä¼¼æ€§çš„æ’å€¼å¡«å……ï¼ˆå¼ºçƒˆæ¨èï¼‰
**åŸç†**: åˆ©ç”¨T2 fså’ŒT2 not fsçš„ç›¸ä¼¼æ€§æ¥ä¼°ç®—gaoqing-T2

#### æŠ€æœ¯å®ç°
```python
def similarity_based_fill(t2_fs_data, t2_not_fs_data, case_id):
    """
    åŸºäºT2æ¨¡æ€ç›¸ä¼¼æ€§çš„gaoqing-T2ä¼°ç®—
    
    åŸç†ï¼šgaoqing-T2 â‰ˆ Î± Ã— T2_fs + Î² Ã— T2_not_fs + Î³ Ã— enhancement
    """
    
    # æ–¹æ³•1: åŠ æƒå¹³å‡ + é”åŒ–
    # gaoqing-T2é€šå¸¸æ¯”æ™®é€šT2æœ‰æ›´å¥½çš„åˆ†è¾¨ç‡å’Œå¯¹æ¯”åº¦
    alpha, beta = 0.6, 0.4  # æƒé‡å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
    
    # åŸºç¡€ä¼°ç®—
    estimated_gaoqing = alpha * t2_fs_data + beta * t2_not_fs_data
    
    # å¢å¼ºå¤„ç†ï¼ˆæ¨¡æ‹Ÿé«˜æ¸…æ•ˆæœï¼‰
    from scipy import ndimage
    
    # 1. è½»å¾®é”åŒ–
    kernel = np.array([[-0.1, -0.1, -0.1],
                      [-0.1,  1.8, -0.1], 
                      [-0.1, -0.1, -0.1]])
    
    enhanced_data = np.zeros_like(estimated_gaoqing)
    for i in range(estimated_gaoqing.shape[2]):  # é€å±‚å¤„ç†
        enhanced_data[:, :, i] = ndimage.convolve(
            estimated_gaoqing[:, :, i], kernel, mode='reflect'
        )
    
    # 2. å¯¹æ¯”åº¦å¢å¼º
    # å¢å¼ºå‰åˆ—è…ºåŒºåŸŸçš„å¯¹æ¯”åº¦
    p2, p98 = np.percentile(enhanced_data, (2, 98))
    enhanced_data = np.clip((enhanced_data - p2) / (p98 - p2), 0, 1)
    
    # 3. æ¢å¤åŸå§‹å¼ºåº¦èŒƒå›´
    original_min = min(t2_fs_data.min(), t2_not_fs_data.min())
    original_max = max(t2_fs_data.max(), t2_not_fs_data.max())
    
    final_data = enhanced_data * (original_max - original_min) + original_min
    
    print(f"   ğŸ¨ ç›¸ä¼¼æ€§å¡«å……: {case_id} çš„ gaoqing-T2 (åŸºäºT2 fs + T2 not fs)")
    
    return final_data.astype(np.float32)
```

**ä¼˜åŠ¿**:
- âœ… ä¿ç•™äº†T2åŠ æƒçš„ç»„ç»‡å¯¹æ¯”ä¿¡æ¯
- âœ… æ¯”0å¡«å……æä¾›æ›´å¤šæœ‰ç”¨ä¿¡æ¯
- âœ… åŸºäºåŒ»å­¦å½±åƒå­¦åŸç†
- âœ… è®¡ç®—æ•ˆç‡é«˜

**åŠ£åŠ¿**:
- âš ï¸ ä¸æ˜¯çœŸå®çš„gaoqing-T2æ•°æ®
- âš ï¸ éœ€è¦è°ƒä¼˜æƒé‡å‚æ•°

### æ–¹æ¡ˆ3: ç»Ÿè®¡å¡«å……
**åŸç†**: ä½¿ç”¨åŒç±»åˆ«ï¼ˆBPH/PCAï¼‰ä¸­å®Œæ•´gaoqing-T2æ•°æ®çš„ç»Ÿè®¡ç‰¹å¾

#### æŠ€æœ¯å®ç°
```python
def statistical_fill(ref_shape, category, case_id, gaoqing_database):
    """
    åŸºäºç»Ÿè®¡ç‰¹å¾çš„å¡«å……
    
    ä½¿ç”¨åŒç±»åˆ«å®Œæ•´gaoqing-T2æ•°æ®çš„å¹³å‡å€¼æˆ–ä¸­ä½æ•°
    """
    
    if category not in gaoqing_database:
        # å¦‚æœæ²¡æœ‰ç»Ÿè®¡æ•°æ®ï¼Œå›é€€åˆ°0å¡«å……
        return np.zeros(ref_shape, dtype=np.float32)
    
    # è·å–åŒç±»åˆ«çš„gaoqing-T2ç»Ÿè®¡æ•°æ®
    category_data = gaoqing_database[category]
    
    # æ–¹æ³•1: ä½¿ç”¨å¹³å‡å€¼
    mean_gaoqing = np.mean(category_data, axis=0)
    
    # æ–¹æ³•2: ä½¿ç”¨ä¸­ä½æ•°ï¼ˆæ›´é²æ£’ï¼‰
    median_gaoqing = np.median(category_data, axis=0)
    
    # æ–¹æ³•3: æ·»åŠ éšæœºå™ªå£°å¢åŠ å¤šæ ·æ€§
    noise_factor = 0.1
    noise = np.random.normal(0, noise_factor * np.std(median_gaoqing), ref_shape)
    
    filled_data = median_gaoqing + noise
    
    print(f"   ğŸ“Š ç»Ÿè®¡å¡«å……: {case_id} çš„ gaoqing-T2 (åŸºäº{category}ç±»åˆ«ç»Ÿè®¡)")
    
    return filled_data.astype(np.float32)
```

**ä¼˜åŠ¿**:
- âœ… åŸºäºçœŸå®æ•°æ®çš„ç»Ÿè®¡ç‰¹å¾
- âœ… ä¿æŒç±»åˆ«ç‰¹å¼‚æ€§
- âœ… å¯ä»¥æ·»åŠ éšæœºæ€§å¢åŠ å¤šæ ·æ€§

**åŠ£åŠ¿**:
- âš ï¸ éœ€è¦é¢„å…ˆæ„å»ºç»Ÿè®¡æ•°æ®åº“
- âš ï¸ ç¼ºä¹ä¸ªä½“ç‰¹å¼‚æ€§
- âš ï¸ å¯èƒ½å¼•å…¥åå·®

### æ–¹æ¡ˆ4: æ·±åº¦å­¦ä¹ ç”Ÿæˆå¡«å……
**åŸç†**: è®­ç»ƒä¸€ä¸ªæ¨¡æ€è½¬æ¢ç½‘ç»œï¼Œä»å…¶ä»–æ¨¡æ€ç”Ÿæˆgaoqing-T2

#### æŠ€æœ¯æ¶æ„
```python
class ModalityGenerator(nn.Module):
    """
    å¤šæ¨¡æ€åˆ°gaoqing-T2çš„ç”Ÿæˆç½‘ç»œ
    
    è¾“å…¥: ADC + DWI + T2_fs + T2_not_fs (4é€šé“)
    è¾“å‡º: gaoqing-T2 (1é€šé“)
    """
    
    def __init__(self):
        super().__init__()
        
        # ç¼–ç å™¨ï¼šæå–å¤šæ¨¡æ€ç‰¹å¾
        self.encoder = nn.Sequential(
            nn.Conv3d(4, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv3d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv3d(64, 128, 3, padding=1),
            nn.ReLU()
        )
        
        # è§£ç å™¨ï¼šç”Ÿæˆgaoqing-T2
        self.decoder = nn.Sequential(
            nn.Conv3d(128, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv3d(64, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv3d(32, 1, 3, padding=1),
            nn.Sigmoid()
        )
    
    def forward(self, multi_modal_input):
        features = self.encoder(multi_modal_input)
        generated_gaoqing = self.decoder(features)
        return generated_gaoqing

def train_modality_generator(complete_cases):
    """
    è®­ç»ƒæ¨¡æ€ç”Ÿæˆå™¨
    
    ä½¿ç”¨å®Œæ•´çš„260ä¾‹æ•°æ®è®­ç»ƒç½‘ç»œ
    """
    model = ModalityGenerator()
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(100):
        for batch in complete_cases:
            # è¾“å…¥ï¼š4ä¸ªæ¨¡æ€
            input_modalities = batch[:, :4, :, :, :]  # ADC, DWI, T2fs, T2notfs
            # ç›®æ ‡ï¼šçœŸå®çš„gaoqing-T2
            target_gaoqing = batch[:, 4:5, :, :, :]   # gaoqing-T2
            
            # å‰å‘ä¼ æ’­
            generated = model(input_modalities)
            loss = criterion(generated, target_gaoqing)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
    
    return model
```

**ä¼˜åŠ¿**:
- âœ… æœ€é«˜è´¨é‡çš„å¡«å……ç»“æœ
- âœ… å­¦ä¹ çœŸå®çš„æ¨¡æ€é—´å…³ç³»
- âœ… ä¸ªä½“åŒ–ç”Ÿæˆ

**åŠ£åŠ¿**:
- âŒ å®ç°å¤æ‚åº¦é«˜
- âŒ éœ€è¦å¤§é‡è®¡ç®—èµ„æº
- âŒ è®­ç»ƒæ—¶é—´é•¿
- âŒ éœ€è¦è¶³å¤Ÿçš„å®Œæ•´æ•°æ®

### æ–¹æ¡ˆ5: å¤šä»»åŠ¡å­¦ä¹ 
**åŸç†**: è®¾è®¡èƒ½å¤Ÿå¤„ç†ç¼ºå¤±æ¨¡æ€çš„nnU-Netæ¶æ„

#### æŠ€æœ¯å®ç°
```python
class MissingModalityAwareUNet(nn.Module):
    """
    ç¼ºå¤±æ¨¡æ€æ„ŸçŸ¥çš„U-Net
    
    èƒ½å¤Ÿè‡ªé€‚åº”å¤„ç†ä¸åŒæ•°é‡çš„è¾“å…¥æ¨¡æ€
    """
    
    def __init__(self, max_modalities=5):
        super().__init__()
        self.max_modalities = max_modalities
        
        # æ¨¡æ€ç‰¹å¼‚æ€§ç¼–ç å™¨
        self.modality_encoders = nn.ModuleList([
            self._create_encoder() for _ in range(max_modalities)
        ])
        
        # æ³¨æ„åŠ›æœºåˆ¶ï¼šè‡ªåŠ¨è°ƒæ•´æ¨¡æ€æƒé‡
        self.attention = nn.MultiheadAttention(embed_dim=256, num_heads=8)
        
        # èåˆç½‘ç»œ
        self.fusion_net = self._create_fusion_network()
        
        # åˆ†å‰²è§£ç å™¨
        self.decoder = self._create_decoder()
    
    def forward(self, x, modality_mask):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥æ•°æ® (B, C, H, W, D)
            modality_mask: æ¨¡æ€æ©ç ï¼ŒæŒ‡ç¤ºå“ªäº›æ¨¡æ€å¯ç”¨
        """
        
        # åˆ†åˆ«ç¼–ç æ¯ä¸ªæ¨¡æ€
        modality_features = []
        for i in range(self.max_modalities):
            if modality_mask[i]:  # æ¨¡æ€å¯ç”¨
                features = self.modality_encoders[i](x[:, i:i+1])
                modality_features.append(features)
            else:  # æ¨¡æ€ç¼ºå¤±ï¼Œä½¿ç”¨é›¶ç‰¹å¾
                zero_features = torch.zeros_like(features)
                modality_features.append(zero_features)
        
        # æ³¨æ„åŠ›èåˆ
        fused_features = self.attention_fusion(modality_features, modality_mask)
        
        # åˆ†å‰²é¢„æµ‹
        segmentation = self.decoder(fused_features)
        
        return segmentation
```

**ä¼˜åŠ¿**:
- âœ… ç«¯åˆ°ç«¯å­¦ä¹ 
- âœ… è‡ªé€‚åº”å¤„ç†ç¼ºå¤±æ¨¡æ€
- âœ… ä¸éœ€è¦é¢„å¡«å……
- âœ… ç†è®ºä¸Šæ•ˆæœæœ€å¥½

**åŠ£åŠ¿**:
- âŒ éœ€è¦é‡æ–°è®¾è®¡ç½‘ç»œæ¶æ„
- âŒ ä¸èƒ½ç›´æ¥ä½¿ç”¨nnU-Net
- âŒ å¼€å‘å‘¨æœŸé•¿

## ğŸ“Š æ–¹æ¡ˆç»¼åˆå¯¹æ¯”

| æ–¹æ¡ˆ | å®ç°éš¾åº¦ | è®¡ç®—æˆæœ¬ | å¡«å……è´¨é‡ | è®­ç»ƒç¨³å®šæ€§ | æ¨èæŒ‡æ•° |
|------|----------|----------|----------|------------|----------|
| 0å¡«å…… | ç®€å• | ä½ | ä½ | é«˜ | â­â­â­ |
| **ç›¸ä¼¼æ€§å¡«å……** | **ä¸­ç­‰** | **ä½** | **ä¸­é«˜** | **é«˜** | **â­â­â­â­â­** |
| ç»Ÿè®¡å¡«å…… | ä¸­ç­‰ | ä¸­ | ä¸­ | é«˜ | â­â­â­â­ |
| æ·±åº¦å­¦ä¹ å¡«å…… | é«˜ | é«˜ | é«˜ | ä¸­ | â­â­â­â­ |
| å¤šä»»åŠ¡å­¦ä¹  | å¾ˆé«˜ | é«˜ | å¾ˆé«˜ | ä¸­ | â­â­â­ |

## ğŸ’¡ æœ€ä½³æ¨èæ–¹æ¡ˆ

### æ¨èæ–¹æ¡ˆ: åŸºäºç›¸ä¼¼æ€§çš„æ’å€¼å¡«å……

**ç†ç”±**:
1. **åŒ»å­¦åˆç†æ€§**: åŸºäºT2åŠ æƒæˆåƒçš„ç‰©ç†åŸç†
2. **å®ç°ç®€å•**: ä¸éœ€è¦é¢å¤–è®­ç»ƒï¼Œè®¡ç®—å¿«é€Ÿ
3. **æ•ˆæœæ˜¾è‘—**: æ¯”0å¡«å……æä¾›æ›´å¤šæœ‰ç”¨ä¿¡æ¯
4. **ç¨³å®šå¯é **: ä¸ä¾èµ–å¤–éƒ¨æ•°æ®æˆ–å¤æ‚æ¨¡å‹

### å®æ–½å»ºè®®

#### ç¬¬ä¸€é˜¶æ®µ: å®ç°ç›¸ä¼¼æ€§å¡«å……
```python
def enhanced_similarity_fill(t2_fs, t2_not_fs, case_id):
    """å¢å¼ºç‰ˆç›¸ä¼¼æ€§å¡«å……"""
    
    # 1. åŸºç¡€åŠ æƒèåˆ
    base_estimate = 0.6 * t2_fs + 0.4 * t2_not_fs
    
    # 2. è¾¹ç¼˜å¢å¼ºï¼ˆæ¨¡æ‹Ÿé«˜æ¸…æ•ˆæœï¼‰
    from scipy import ndimage
    enhanced = ndimage.gaussian_filter(base_estimate, sigma=0.5)
    enhanced = base_estimate + 0.3 * (base_estimate - enhanced)
    
    # 3. å¯¹æ¯”åº¦ä¼˜åŒ–
    p1, p99 = np.percentile(enhanced, (1, 99))
    enhanced = np.clip(enhanced, p1, p99)
    
    # 4. å¼ºåº¦å½’ä¸€åŒ–
    enhanced = (enhanced - enhanced.min()) / (enhanced.max() - enhanced.min())
    enhanced = enhanced * (t2_fs.max() - t2_fs.min()) + t2_fs.min()
    
    return enhanced.astype(np.float32)
```

#### ç¬¬äºŒé˜¶æ®µ: å‚æ•°ä¼˜åŒ–
- æ ¹æ®å®Œæ•´æ•°æ®éªŒè¯æœ€ä½³æƒé‡
- è°ƒæ•´å¢å¼ºå‚æ•°
- è¯„ä¼°å¡«å……è´¨é‡

#### ç¬¬ä¸‰é˜¶æ®µ: æ•ˆæœéªŒè¯
- å¯¹æ¯”ä¸åŒå¡«å……æ–¹æ³•çš„åˆ†å‰²æ•ˆæœ
- åˆ†æç½‘ç»œå­¦ä¹ åˆ°çš„ç‰¹å¾
- ä¼˜åŒ–å¡«å……ç­–ç•¥

## ğŸ”§ å®ç°è®¡åˆ’

### çŸ­æœŸç›®æ ‡ï¼ˆ1-2å‘¨ï¼‰
1. å®ç°åŸºäºç›¸ä¼¼æ€§çš„æ’å€¼å¡«å……
2. é›†æˆåˆ°ç°æœ‰è½¬æ¢è„šæœ¬
3. è¿›è¡Œåˆæ­¥æ•ˆæœéªŒè¯

### ä¸­æœŸç›®æ ‡ï¼ˆ1ä¸ªæœˆï¼‰
1. ä¼˜åŒ–å¡«å……å‚æ•°
2. å®ç°ç»Ÿè®¡å¡«å……ä½œä¸ºå¤‡é€‰
3. å®Œæˆæ€§èƒ½å¯¹æ¯”åˆ†æ

### é•¿æœŸç›®æ ‡ï¼ˆ2-3ä¸ªæœˆï¼‰
1. æ¢ç´¢æ·±åº¦å­¦ä¹ å¡«å……æ–¹æ³•
2. ç ”ç©¶å¤šä»»åŠ¡å­¦ä¹ æ¶æ„
3. å‘è¡¨ç›¸å…³æŠ€æœ¯è®ºæ–‡

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### ç›¸ä¼¼æ€§å¡«å……é¢„æœŸç»“æœ
- **æ•°æ®åˆ©ç”¨ç‡**: 100%ï¼ˆ459ä¾‹ï¼‰
- **é€šé“ä¸€è‡´æ€§**: å®Œç¾ï¼ˆ5é€šé“ï¼‰
- **å¡«å……è´¨é‡**: ä¸­é«˜ï¼ˆä¿ç•™T2å¯¹æ¯”ä¿¡æ¯ï¼‰
- **é¢„æœŸDice**: 0.84-0.87ï¼ˆæ¯”0å¡«å……æå‡2-3%ï¼‰
- **è®­ç»ƒç¨³å®šæ€§**: ä¼˜ç§€

### ä¸å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”
```
æ–¹æ¡ˆæ•ˆæœæ’åºï¼ˆé¢„æœŸï¼‰:
1. æ·±åº¦å­¦ä¹ å¡«å……: Dice 0.86-0.89
2. ç›¸ä¼¼æ€§å¡«å……: Dice 0.84-0.87  â† æ¨è
3. ç»Ÿè®¡å¡«å……: Dice 0.83-0.86
4. 0å¡«å……: Dice 0.83-0.86
5. æ ¸å¿ƒ4æ¨¡æ€: Dice 0.82-0.85
```

---

**ç»“è®º**: åŸºäºç›¸ä¼¼æ€§çš„æ’å€¼å¡«å……æ˜¯å½“å‰æœ€ä½³çš„å®ç”¨æ–¹æ¡ˆï¼Œåœ¨å®ç°å¤æ‚åº¦ã€è®¡ç®—æˆæœ¬å’Œæ•ˆæœä¹‹é—´è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ã€‚å»ºè®®ä¼˜å…ˆå®ç°è¿™ä¸ªæ–¹æ¡ˆã€‚