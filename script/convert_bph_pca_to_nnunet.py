#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BPH-PCAå¤šæ¨¡æ€å‰åˆ—è…ºMRIæ•°æ®è½¬æ¢ä¸ºnnU-Net v2æ ¼å¼

è¯¥è„šæœ¬å°†BPH-PCAæ•°æ®é›†è½¬æ¢ä¸ºnnU-Net v2æ‰€éœ€çš„æ ¼å¼ï¼š
- æ”¯æŒå¤šæ¨¡æ€MRIæ•°æ®ï¼ˆADC, DWI, T2ç­‰ï¼‰
- è‡ªåŠ¨å¤„ç†BPHå’ŒPCAä¸¤ç±»æ•°æ®
- ç”Ÿæˆç¬¦åˆnnU-Net v2å‘½åè§„èŒƒçš„æ–‡ä»¶
- åˆ›å»ºæ•°æ®é›†æè¿°æ–‡ä»¶
"""

import json
import argparse
from pathlib import Path
from typing import Dict, List, Tuple
import nibabel as nib
import numpy as np
from tqdm import tqdm
from scipy import ndimage
from scipy.ndimage import zoom

class BPHPCAToNnUNetConverter:
    """BPH-PCAæ•°æ®è½¬æ¢å™¨"""
    
    def __init__(self, source_dir: str, output_dir: str, dataset_id: int = 1, 
                 processing_mode: str = 'zero_fill'):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨
        
        Args:
            source_dir: BPH-PCAæ•°æ®æºç›®å½•
            output_dir: nnU-Netè¾“å‡ºç›®å½•
            dataset_id: æ•°æ®é›†IDï¼ˆé»˜è®¤1ï¼‰
            processing_mode: å¤„ç†æ¨¡å¼ ('core_4', 'zero_fill', 'strict_5')
        """
        self.source_dir = Path(source_dir)
        self.output_dir = Path(output_dir)
        self.dataset_id = dataset_id
        self.dataset_name = f"Dataset{dataset_id:03d}_BPH_PCA"
        self.processing_mode = processing_mode
        
        # æ ¹æ®å¤„ç†æ¨¡å¼è®¾ç½®å‚æ•°
        if processing_mode == 'core_4':
            # åªä½¿ç”¨4ä¸ªæ ¸å¿ƒæ¨¡æ€
            self.modality_mapping = {
                'ADC': '0000',
                'DWI': '0001', 
                'T2 fs': '0002',
                'T2 not fs': '0003'
            }
            self.zero_fill_missing = False
            self.min_modalities = 4
            print("ğŸ”§ æ ¸å¿ƒæ¨¡æ€æ¨¡å¼ï¼šä½¿ç”¨ADC, DWI, T2 fs, T2 not fsï¼ˆ4é€šé“ï¼‰")
            
        elif processing_mode == 'zero_fill':
            # ä½¿ç”¨5ä¸ªæ¨¡æ€ï¼Œç¼ºå¤±çš„ç”¨0å¡«å……
            self.modality_mapping = {
                'ADC': '0000',
                'DWI': '0001', 
                'T2 fs': '0002',
                'T2 not fs': '0003',
                'gaoqing-T2': '0004'
            }
            self.zero_fill_missing = True
            self.min_modalities = 4
            print("ğŸ”§ 0å¡«å……æ¨¡å¼ï¼šä½¿ç”¨5ä¸ªæ¨¡æ€ï¼Œç¼ºå¤±çš„gaoqing-T2ç”¨0å¡«å……ï¼ˆ5é€šé“ï¼‰")
            
        elif processing_mode == 'similarity_fill':
            # ä½¿ç”¨5ä¸ªæ¨¡æ€ï¼Œç¼ºå¤±çš„ç”¨ç›¸ä¼¼æ€§å¡«å……
            self.modality_mapping = {
                'ADC': '0000',
                'DWI': '0001', 
                'T2 fs': '0002',
                'T2 not fs': '0003',
                'gaoqing-T2': '0004'
            }
            self.zero_fill_missing = True
            self.similarity_fill = True
            self.min_modalities = 4
            print("ğŸ”§ ç›¸ä¼¼æ€§å¡«å……æ¨¡å¼ï¼šä½¿ç”¨5ä¸ªæ¨¡æ€ï¼Œç¼ºå¤±çš„gaoqing-T2ç”¨ç›¸ä¼¼æ€§å¡«å……ï¼ˆ5é€šé“ï¼‰")
            
        elif processing_mode == 'strict_5':
            # ä¸¥æ ¼è¦æ±‚æ‰€æœ‰5ä¸ªæ¨¡æ€
            self.modality_mapping = {
                'ADC': '0000',
                'DWI': '0001', 
                'T2 fs': '0002',
                'T2 not fs': '0003',
                'gaoqing-T2': '0004'
            }
            self.zero_fill_missing = False
            self.min_modalities = 5
            print("ğŸ”§ ä¸¥æ ¼æ¨¡å¼ï¼šè¦æ±‚æ‰€æœ‰5ä¸ªæ¨¡æ€éƒ½å­˜åœ¨ï¼ˆ5é€šé“ï¼‰")
            
        else:
            raise ValueError(f"æœªçŸ¥çš„å¤„ç†æ¨¡å¼: {processing_mode}")
        
        # è®¾ç½®ç›¸ä¼¼æ€§å¡«å……æ ‡å¿—
        if not hasattr(self, 'similarity_fill'):
            self.similarity_fill = False
        
        # å›ºå®šå‚æ•°
        self.enable_resampling = True  # å§‹ç»ˆå¯ç”¨é‡é‡‡æ ·
        
        # ç±»åˆ«æ ‡ç­¾
        self.label_mapping = {
            'BPH': 1,  # è‰¯æ€§å‰åˆ—è…ºå¢ç”Ÿ
            'PCA': 2   # å‰åˆ—è…ºç™Œ
        }
        
        self._setup_directories()
    
    def _resample_image(self, image_data: np.ndarray, target_shape: tuple, 
                       case_id: str, modality: str) -> np.ndarray:
        """
        é‡é‡‡æ ·å›¾åƒåˆ°ç›®æ ‡å½¢çŠ¶
        
        Args:
            image_data: åŸå§‹å›¾åƒæ•°æ®
            target_shape: ç›®æ ‡å½¢çŠ¶
            case_id: ç—…ä¾‹ID
            modality: æ¨¡æ€åç§°
            
        Returns:
            é‡é‡‡æ ·åçš„å›¾åƒæ•°æ®
        """
        if image_data.shape == target_shape:
            return image_data
        
        # è®¡ç®—ç¼©æ”¾å› å­
        zoom_factors = [target_shape[i] / image_data.shape[i] for i in range(len(target_shape))]
        
        print(f"   ğŸ”„ é‡é‡‡æ · {case_id} çš„ {modality}: {image_data.shape} -> {target_shape}")
        
        # ä½¿ç”¨ä¸‰æ¬¡æ ·æ¡æ’å€¼è¿›è¡Œé‡é‡‡æ ·
        try:
            resampled_data = zoom(image_data, zoom_factors, order=1, mode='nearest')
            
            # ç¡®ä¿è¾“å‡ºå½¢çŠ¶æ­£ç¡®ï¼ˆç”±äºæµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜å¯èƒ½æœ‰å¾®å°å·®å¼‚ï¼‰
            if resampled_data.shape != target_shape:
                # å¦‚æœå½¢çŠ¶ä»ä¸åŒ¹é…ï¼Œä½¿ç”¨è£å‰ªæˆ–å¡«å……
                resampled_data = self._adjust_shape(resampled_data, target_shape)
            
            return resampled_data.astype(np.float32)
            
        except Exception as e:
            print(f"   âŒ é‡é‡‡æ ·å¤±è´¥ {case_id} çš„ {modality}: {e}")
            return None
    
    def _adjust_shape(self, data: np.ndarray, target_shape: tuple) -> np.ndarray:
        """
        é€šè¿‡è£å‰ªæˆ–å¡«å……è°ƒæ•´æ•°æ®å½¢çŠ¶
        """
        current_shape = data.shape
        adjusted_data = data.copy()
        
        for i in range(len(target_shape)):
            if current_shape[i] > target_shape[i]:
                # è£å‰ª
                slice_obj = [slice(None)] * len(current_shape)
                slice_obj[i] = slice(0, target_shape[i])
                adjusted_data = adjusted_data[tuple(slice_obj)]
            elif current_shape[i] < target_shape[i]:
                # å¡«å……
                pad_width = [(0, 0)] * len(current_shape)
                pad_width[i] = (0, target_shape[i] - current_shape[i])
                adjusted_data = np.pad(adjusted_data, pad_width, mode='constant', constant_values=0)
        
        return adjusted_data
    
    def _similarity_fill_gaoqing_t2(self, t2_fs_data: np.ndarray, 
                                   t2_not_fs_data: np.ndarray, 
                                   case_id: str) -> np.ndarray:
        """
        åŸºäºT2æ¨¡æ€ç›¸ä¼¼æ€§å¡«å……gaoqing-T2
        
        åŸç†: gaoqing-T2 â‰ˆ enhanced(Î± Ã— T2_fs + Î² Ã— T2_not_fs)
        """
        print(f"   ğŸ¨ ç›¸ä¼¼æ€§å¡«å……: {case_id} çš„ gaoqing-T2 (åŸºäºT2 fs + T2 not fs)")
        
        # å‚æ•°è®¾ç½®
        t2_fs_weight = 0.6      # T2 fsæƒé‡ï¼ˆé€šå¸¸å¯¹æ¯”åº¦æ›´å¥½ï¼‰
        t2_not_fs_weight = 0.4  # T2 not fsæƒé‡
        enhancement_factor = 0.3 # è¾¹ç¼˜å¢å¼ºå› å­
        sigma = 0.5             # é«˜æ–¯æ»¤æ³¢å‚æ•°
        
        # æ­¥éª¤1: åŸºç¡€åŠ æƒèåˆ
        base_estimate = t2_fs_weight * t2_fs_data + t2_not_fs_weight * t2_not_fs_data
        
        # æ­¥éª¤2: è¾¹ç¼˜å¢å¼ºï¼ˆæ¨¡æ‹Ÿé«˜æ¸…æ•ˆæœï¼‰
        smoothed = ndimage.gaussian_filter(base_estimate, sigma=sigma)
        enhanced = base_estimate + enhancement_factor * (base_estimate - smoothed)
        
        # æ­¥éª¤3: å¯¹æ¯”åº¦ä¼˜åŒ–
        p1, p99 = np.percentile(enhanced, (1, 99))
        enhanced = np.clip(enhanced, p1, p99)
        
        # æ­¥éª¤4: å¼ºåº¦å½’ä¸€åŒ–åˆ°åˆç†èŒƒå›´
        original_min = min(t2_fs_data.min(), t2_not_fs_data.min())
        original_max = max(t2_fs_data.max(), t2_not_fs_data.max())
        
        enhanced_norm = (enhanced - enhanced.min()) / (enhanced.max() - enhanced.min())
        normalized = enhanced_norm * (original_max - original_min) + original_min
        
        # æ­¥éª¤5: ç»†å¾®çº¹ç†å¢å¼º
        texture_kernel = np.array([[-0.05, -0.1, -0.05],
                                  [-0.1,   1.4, -0.1], 
                                  [-0.05, -0.1, -0.05]])
        
        textured_data = np.zeros_like(normalized)
        for i in range(normalized.shape[2]):  # é€å±‚å¤„ç†
            textured_data[:, :, i] = ndimage.convolve(
                normalized[:, :, i], texture_kernel, mode='reflect'
            )
        
        # æ­¥éª¤6: æ··åˆåŸå§‹å’Œçº¹ç†å¢å¼ºç‰ˆæœ¬
        final_result = 0.8 * normalized + 0.2 * textured_data
        
        # ç¡®ä¿æ•°æ®ç±»å‹å’ŒèŒƒå›´
        final_result = np.clip(final_result, original_min, original_max)
        
        print(f"     âœ… ç›¸ä¼¼æ€§å¡«å……å®Œæˆ: å¼ºåº¦èŒƒå›´ [{final_result.min():.2f}, {final_result.max():.2f}]")
        
        return final_result.astype(np.float32)
    
    def _setup_directories(self):
        """åˆ›å»ºnnU-Netç›®å½•ç»“æ„"""
        self.dataset_dir = self.output_dir / self.dataset_name
        self.images_tr_dir = self.dataset_dir / "imagesTr"
        self.labels_tr_dir = self.dataset_dir / "labelsTr"
        self.images_ts_dir = self.dataset_dir / "imagesTs"
        
        # åˆ›å»ºç›®å½•
        for dir_path in [self.images_tr_dir, self.labels_tr_dir, self.images_ts_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
            
        print(f"âœ“ åˆ›å»ºæ•°æ®é›†ç›®å½•: {self.dataset_dir}")
    

    
    def _check_modalities_for_case(self, case_id: str, category: str) -> Dict[str, Path]:
        """æ£€æŸ¥æŸä¸ªç—…ä¾‹çš„æ‰€æœ‰æ¨¡æ€æ–‡ä»¶"""
        available_modalities = {}
        category_dir = self.source_dir / category
        
        for modality, _ in self.modality_mapping.items():
            modality_dir = category_dir / modality
            nii_file = modality_dir / f"{case_id}.nii"
            
            if nii_file.exists():
                available_modalities[modality] = nii_file
        
        return available_modalities
    
    def _validate_case_completeness(self, case_id: str, category: str) -> Tuple[bool, Dict[str, Path]]:
        """éªŒè¯ç—…ä¾‹æ•°æ®å®Œæ•´æ€§"""
        modalities = self._check_modalities_for_case(case_id, category)
        
        # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶
        roi_dir = self.source_dir / "ROI(BPH+PCA)" / category
        label_file = roi_dir / f"{case_id}.nii"
        if not label_file.exists():
            print(f"âš ï¸  è·³è¿‡ {case_id}: æ²¡æœ‰æ ‡ç­¾æ–‡ä»¶")
            return False, {}
        
        # æ£€æŸ¥æ¨¡æ€å®Œæ•´æ€§
        if self.processing_mode == 'strict_5':
            # ä¸¥æ ¼æ¨¡å¼ï¼šè¦æ±‚æ‰€æœ‰5ä¸ªæ¨¡æ€éƒ½å­˜åœ¨
            missing_modalities = set(self.modality_mapping.keys()) - set(modalities.keys())
            if missing_modalities:
                print(f"âš ï¸  è·³è¿‡ {case_id}: ç¼ºå°‘æ¨¡æ€ {missing_modalities}")
                return False, {}
        else:
            # å…¶ä»–æ¨¡å¼ï¼šè‡³å°‘éœ€è¦4ä¸ªæ ¸å¿ƒæ¨¡æ€
            core_modalities = {'ADC', 'DWI', 'T2 fs', 'T2 not fs'}
            available_core = set(modalities.keys()) & core_modalities
            if len(available_core) < 4:
                missing_core = core_modalities - available_core
                print(f"âš ï¸  è·³è¿‡ {case_id}: ç¼ºå°‘æ ¸å¿ƒæ¨¡æ€ {missing_core}")
                return False, {}
        
        return True, modalities
    
    def _combine_modalities(self, modalities: Dict[str, Path], case_id: str) -> str:
        """åˆå¹¶å¤šæ¨¡æ€æ•°æ®ä¸ºnnU-Netæ ¼å¼"""
        # ç¡®å®šè¦å¤„ç†çš„æ¨¡æ€åˆ—è¡¨
        if self.zero_fill_missing:
            # 0å¡«å……æ¨¡å¼ï¼šå¤„ç†æ‰€æœ‰å®šä¹‰çš„æ¨¡æ€
            target_modalities = list(self.modality_mapping.keys())
            num_channels = len(target_modalities)
        else:
            # å¸¸è§„æ¨¡å¼ï¼šåªå¤„ç†å¯ç”¨çš„æ¨¡æ€
            target_modalities = [m for m in self.modality_mapping.keys() if m in modalities]
            num_channels = len(target_modalities)
        
        if not target_modalities:
            raise ValueError(f"æ²¡æœ‰å¯ç”¨çš„æ¨¡æ€æ•°æ®")
        
        # è¯»å–ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡æ€ä½œä¸ºå‚è€ƒ
        reference_modality = None
        for modality in target_modalities:
            if modality in modalities:
                reference_modality = modality
                break
        
        if not reference_modality:
            raise ValueError(f"æ²¡æœ‰æ‰¾åˆ°å‚è€ƒæ¨¡æ€")
        
        ref_img = nib.load(modalities[reference_modality])
        ref_shape = ref_img.shape
        ref_affine = ref_img.affine
        
        # åˆ›å»ºå¤šé€šé“æ•°æ®
        combined_data = np.zeros((*ref_shape, num_channels), dtype=np.float32)
        valid_channels = 0
        missing_modalities = []
        
        for i, modality in enumerate(target_modalities):
            if modality in modalities:
                # å¤„ç†å­˜åœ¨çš„æ¨¡æ€
                try:
                    file_path = modalities[modality]
                    img = nib.load(file_path)
                    data = img.get_fdata().astype(np.float32)
                    
                    # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦ä¸€è‡´
                    if data.shape != ref_shape:
                        if self.enable_resampling:
                            # å°è¯•é‡é‡‡æ ·
                            resampled_data = self._resample_image(data, ref_shape, case_id, modality)
                            if resampled_data is not None:
                                data = resampled_data
                            else:
                                if self.zero_fill_missing:
                                    print(f"   ğŸ”„ é‡é‡‡æ ·å¤±è´¥ï¼Œä½¿ç”¨0å¡«å……: {case_id} çš„ {modality}")
                                    data = np.zeros(ref_shape, dtype=np.float32)
                                    missing_modalities.append(modality)
                                else:
                                    print(f"âš ï¸  è·³è¿‡: {case_id} çš„ {modality} æ¨¡æ€é‡é‡‡æ ·å¤±è´¥")
                                    continue
                        else:
                            if self.zero_fill_missing:
                                print(f"   ğŸ”„ å½¢çŠ¶ä¸ä¸€è‡´ï¼Œä½¿ç”¨0å¡«å……: {case_id} çš„ {modality}")
                                data = np.zeros(ref_shape, dtype=np.float32)
                                missing_modalities.append(modality)
                            else:
                                print(f"âš ï¸  è·³è¿‡: {case_id} çš„ {modality} æ¨¡æ€å½¢çŠ¶ä¸ä¸€è‡´: {data.shape} vs {ref_shape}")
                                continue
                    
                    combined_data[..., i] = data
                    valid_channels += 1
                    
                except Exception as e:
                    if self.zero_fill_missing:
                        print(f"   ğŸ”„ è¯»å–å¤±è´¥ï¼Œä½¿ç”¨0å¡«å……: {case_id} çš„ {modality}")
                        combined_data[..., i] = np.zeros(ref_shape, dtype=np.float32)
                        missing_modalities.append(modality)
                        valid_channels += 1
                    else:
                        print(f"âš ï¸  è­¦å‘Š: è¯»å– {case_id} çš„ {modality} æ¨¡æ€å¤±è´¥: {e}")
                        continue
            else:
                # å¤„ç†ç¼ºå¤±çš„æ¨¡æ€
                if self.zero_fill_missing:
                    if self.similarity_fill and modality == 'gaoqing-T2':
                        # å¯¹gaoqing-T2ä½¿ç”¨ç›¸ä¼¼æ€§å¡«å……
                        if 'T2 fs' in modalities and 'T2 not fs' in modalities:
                            try:
                                # åŠ è½½T2æ¨¡æ€æ•°æ®
                                t2_fs_img = nib.load(modalities['T2 fs'])
                                t2_not_fs_img = nib.load(modalities['T2 not fs'])
                                
                                t2_fs_data = t2_fs_img.get_fdata().astype(np.float32)
                                t2_not_fs_data = t2_not_fs_img.get_fdata().astype(np.float32)
                                
                                # é‡é‡‡æ ·åˆ°å‚è€ƒå½¢çŠ¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
                                if t2_fs_data.shape != ref_shape:
                                    t2_fs_data = self._resample_image(t2_fs_data, ref_shape, case_id, 'T2 fs')
                                if t2_not_fs_data.shape != ref_shape:
                                    t2_not_fs_data = self._resample_image(t2_not_fs_data, ref_shape, case_id, 'T2 not fs')
                                
                                # æ‰§è¡Œç›¸ä¼¼æ€§å¡«å……
                                filled_data = self._similarity_fill_gaoqing_t2(
                                    t2_fs_data, t2_not_fs_data, case_id
                                )
                                combined_data[..., i] = filled_data
                                
                            except Exception as e:
                                print(f"   âŒ ç›¸ä¼¼æ€§å¡«å……å¤±è´¥ï¼Œä½¿ç”¨0å¡«å……: {case_id} - {e}")
                                combined_data[..., i] = np.zeros(ref_shape, dtype=np.float32)
                                missing_modalities.append(modality)
                        else:
                            print(f"   âš ï¸  ç¼ºå°‘T2æ¨¡æ€ï¼Œä½¿ç”¨0å¡«å……: {case_id} çš„ {modality}")
                            combined_data[..., i] = np.zeros(ref_shape, dtype=np.float32)
                            missing_modalities.append(modality)
                    else:
                        # å…¶ä»–æ¨¡æ€ä½¿ç”¨0å¡«å……
                        print(f"   ğŸ”„ æ¨¡æ€ç¼ºå¤±ï¼Œä½¿ç”¨0å¡«å……: {case_id} çš„ {modality}")
                        combined_data[..., i] = np.zeros(ref_shape, dtype=np.float32)
                        missing_modalities.append(modality)
                    
                    valid_channels += 1
                # å¦‚æœä¸æ˜¯0å¡«å……æ¨¡å¼ï¼Œç›´æ¥è·³è¿‡ç¼ºå¤±çš„æ¨¡æ€
        
        if valid_channels == 0:
            raise ValueError(f"æ²¡æœ‰æœ‰æ•ˆçš„æ¨¡æ€æ•°æ®")
        
        # 0å¡«å……æ¨¡å¼ä¸‹ä¸éœ€è¦è£å‰ªï¼Œå› ä¸ºæ‰€æœ‰é€šé“éƒ½å·²å¡«å……
        if not self.zero_fill_missing and valid_channels < num_channels:
            combined_data = combined_data[..., :valid_channels]
        
        # è¾“å‡º0å¡«å……ç»Ÿè®¡ä¿¡æ¯
        if missing_modalities:
            print(f"   ğŸ“Š {case_id} 0å¡«å……æ¨¡æ€: {missing_modalities}")
        
        # ä¿å­˜åˆå¹¶åçš„å›¾åƒ
        output_filename = f"{case_id}_{self.dataset_id:03d}.nii.gz"
        output_path = self.images_tr_dir / output_filename
        
        # åˆ›å»ºåˆé€‚çš„header
        header = nib.Nifti1Header()
        header.set_data_dtype(np.float32)
        
        combined_img = nib.Nifti1Image(combined_data, ref_affine, header)
        nib.save(combined_img, output_path)
        
        return output_filename
    
    def _process_label(self, case_id: str, category: str) -> str:
        """å¤„ç†æ ‡ç­¾æ–‡ä»¶"""
        roi_dir = self.source_dir / "ROI(BPH+PCA)" / category
        label_file = roi_dir / f"{case_id}.nii"
        
        if not label_file.exists():
            print(f"âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ° {case_id} çš„æ ‡ç­¾æ–‡ä»¶")
            return None
        
        # è¯»å–æ ‡ç­¾
        label_img = nib.load(label_file)
        label_data = label_img.get_fdata().astype(np.uint8)
        
        # å°†æ ‡ç­¾å€¼æ˜ å°„ä¸ºç±»åˆ«
        label_value = self.label_mapping[category]
        label_data = np.where(label_data > 0, label_value, 0)
        
        # ä¿å­˜æ ‡ç­¾
        output_filename = f"{case_id}_{self.dataset_id:03d}.nii.gz"
        output_path = self.labels_tr_dir / output_filename
        
        # åˆ›å»ºåˆé€‚çš„header
        header = nib.Nifti1Header()
        header.set_data_dtype(np.uint8)
        
        label_img_new = nib.Nifti1Image(label_data, label_img.affine, header)
        nib.save(label_img_new, output_path)
        
        return output_filename
    
    def _create_dataset_json(self, processed_cases: List[Dict]):
        """åˆ›å»ºdataset.jsonæ–‡ä»¶"""
        # ç»Ÿè®¡æ¨¡æ€ä¿¡æ¯
        all_modalities = set()
        for case in processed_cases:
            all_modalities.update(case['modalities'])
        
        modality_dict = {}
        for i, modality in enumerate(sorted(all_modalities)):
            modality_dict[str(i)] = modality
        
        dataset_json = {
            "channel_names": modality_dict,
            "labels": {
                "background": 0,
                "BPH": 1,
                "PCA": 2
            },
            "numTraining": len(processed_cases),
            "file_ending": ".nii.gz",
            "overwrite_image_reader_writer": "SimpleITKIO",
            "dataset_name": self.dataset_name,
            "description": "BPH-PCAå¤šæ¨¡æ€å‰åˆ—è…ºMRIåˆ†å‰²æ•°æ®é›†",
            "reference": "BPH-PCA Dataset for Prostate Segmentation",
            "licence": "ç ”ç©¶ä½¿ç”¨",
            "tensorImageSize": "3D"
        }
        
        # ä¿å­˜dataset.json
        json_path = self.dataset_dir / "dataset.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(dataset_json, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ åˆ›å»ºdataset.json: {json_path}")
        return dataset_json
    
    def convert(self):
        """æ‰§è¡Œæ•°æ®è½¬æ¢"""
        print(f"ğŸš€ å¼€å§‹è½¬æ¢BPH-PCAæ•°æ®é›†åˆ°nnU-Net v2æ ¼å¼...")
        print(f"ğŸ“ æºç›®å½•: {self.source_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.dataset_dir}")
        
        processed_cases = []
        
        # å¤„ç†BPHå’ŒPCAæ•°æ®
        for category in ['BPH', 'PCA']:
            print(f"\nğŸ“‹ å¤„ç† {category} æ•°æ®...")
            
            category_dir = self.source_dir / category
            if not category_dir.exists():
                print(f"âš ï¸  è·³è¿‡ä¸å­˜åœ¨çš„ç›®å½•: {category_dir}")
                continue
            
            # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰ç—…ä¾‹
            case_ids = set()
            for modality_dir in category_dir.iterdir():
                if modality_dir.is_dir():
                    for nii_file in modality_dir.glob("*.nii"):
                        case_ids.add(nii_file.stem)
            
            case_ids = sorted(list(case_ids))
            print(f"   æ‰¾åˆ° {len(case_ids)} ä¸ª {category} ç—…ä¾‹")
            
            # å¤„ç†æ¯ä¸ªç—…ä¾‹
            for case_id in tqdm(case_ids, desc=f"å¤„ç†{category}"):
                # éªŒè¯ç—…ä¾‹å®Œæ•´æ€§
                is_valid, modalities = self._validate_case_completeness(case_id, category)
                
                if not is_valid:
                    continue
                
                # åˆå¹¶å¤šæ¨¡æ€æ•°æ®
                try:
                    image_filename = self._combine_modalities(modalities, case_id)
                    label_filename = self._process_label(case_id, category)
                    
                    if image_filename and label_filename:
                        processed_cases.append({
                            'case_id': case_id,
                            'category': category,
                            'modalities': list(modalities.keys()),
                            'image_file': image_filename,
                            'label_file': label_filename
                        })
                
                except Exception as e:
                    print(f"âŒ å¤„ç† {case_id} æ—¶å‡ºé”™: {e}")
                    continue
        
        print(f"\nâœ… æˆåŠŸå¤„ç† {len(processed_cases)} ä¸ªç—…ä¾‹")
        
        # åˆ›å»ºdataset.json
        dataset_info = self._create_dataset_json(processed_cases)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self._print_statistics(processed_cases, dataset_info)
        
        return processed_cases
    
    def _print_statistics(self, processed_cases: List[Dict], dataset_info: Dict):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»ç—…ä¾‹æ•°: {len(processed_cases)}")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        category_counts = {}
        for case in processed_cases:
            category = case['category']
            category_counts[category] = category_counts.get(category, 0) + 1
        
        for category, count in category_counts.items():
            print(f"   {category}: {count} ä¾‹")
        
        # æ¨¡æ€ç»Ÿè®¡
        modality_counts = {}
        for case in processed_cases:
            for modality in case['modalities']:
                modality_counts[modality] = modality_counts.get(modality, 0) + 1
        
        print(f"\n   å¯ç”¨æ¨¡æ€:")
        for modality, count in modality_counts.items():
            print(f"   {modality}: {count} ä¾‹")
        
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   å›¾åƒç›®å½•: {self.images_tr_dir}")
        print(f"   æ ‡ç­¾ç›®å½•: {self.labels_tr_dir}")
        print(f"   é…ç½®æ–‡ä»¶: {self.dataset_dir}/dataset.json")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å°†BPH-PCAæ•°æ®è½¬æ¢ä¸ºnnU-Net v2æ ¼å¼')
    parser.add_argument('--source_dir', type=str, default='data/BPH-PCA',
                       help='BPH-PCAæ•°æ®æºç›®å½•')
    parser.add_argument('--output_dir', type=str, default='nnUNet_raw',
                       help='nnU-Netè¾“å‡ºç›®å½•')
    parser.add_argument('--dataset_id', type=int, default=1,
                       help='æ•°æ®é›†ID')
    parser.add_argument('--mode', type=str, default='similarity_fill',
                       choices=['core_4', 'zero_fill', 'similarity_fill', 'strict_5'],
                       help='å¤„ç†æ¨¡å¼: core_4(4é€šé“), zero_fill(5é€šé“0å¡«å……), similarity_fill(5é€šé“ç›¸ä¼¼æ€§å¡«å……), strict_5(ä¸¥æ ¼5é€šé“)')
    
    args = parser.parse_args()
    
    mode_descriptions = {
        'core_4': 'æ ¸å¿ƒ4æ¨¡æ€æ¨¡å¼ï¼ˆADC, DWI, T2 fs, T2 not fsï¼‰',
        'zero_fill': '0å¡«å……5æ¨¡æ€æ¨¡å¼ï¼ˆç¼ºå¤±gaoqing-T2ç”¨0å¡«å……ï¼‰',
        'similarity_fill': 'ç›¸ä¼¼æ€§å¡«å……5æ¨¡æ€æ¨¡å¼ï¼ˆç¼ºå¤±gaoqing-T2ç”¨ç›¸ä¼¼æ€§å¡«å……ï¼‰',
        'strict_5': 'ä¸¥æ ¼5æ¨¡æ€æ¨¡å¼ï¼ˆè¦æ±‚æ‰€æœ‰æ¨¡æ€éƒ½å­˜åœ¨ï¼‰'
    }
    
    print(f"ğŸ”§ æ•°æ®å¤„ç†è®¾ç½®:")
    print(f"   å¤„ç†æ¨¡å¼: {mode_descriptions[args.mode]}")
    print(f"   æ•°æ®é›†ID: {args.dataset_id}")
    
    # åˆ›å»ºè½¬æ¢å™¨å¹¶æ‰§è¡Œè½¬æ¢
    converter = BPHPCAToNnUNetConverter(
        source_dir=args.source_dir,
        output_dir=args.output_dir,
        dataset_id=args.dataset_id,
        processing_mode=args.mode
    )
    
    processed_cases = converter.convert()
    
    print(f"\nğŸ‰ æ•°æ®è½¬æ¢å®Œæˆï¼")
    print(f"ğŸ’¡ æ¥ä¸‹æ¥å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡ŒnnU-Netè®­ç»ƒ:")
    print(f"   nnUNetv2_plan_and_preprocess -d {args.dataset_id}")
    print(f"   nnUNetv2_train {args.dataset_id} 3d_fullres 0")


if __name__ == "__main__":
    main()
